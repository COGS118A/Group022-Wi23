{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Neil Bajaj\n",
    "- Ria Singh\n",
    "- Pratheek Sankeshi \n",
    "- Shenova Davis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal of this project is to predict whether to approve a credit card for an applicant based on a variety of factors that were asked on their application. We will predict using a machine learning algorithm. The data we will be using is from the Kaggle dataset: A Credit Card Dataset for Machine Learning. The link is https://www.kaggle.com/datasets/caesarmario/application-data/. We will be using factors such as Total Income, Education Type, Applicant Age, etc. More will be described in the data section. Furthermore, we will drop unnecessary columns like Owned Phone, Owned Email, etc while also replacing null values to perform EDA. We will then run various supervised machine learning algorithms to create models to predict the data and use the best one. The performance will be measured on how accurately we predict the data against the status column of the data which is whether the application was approved or not. \n",
    "\n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "As we get deeper into the age of Big Data, we see that, where possible, we are attempting to move from human evaluation to machine learning prediction. There has also been an uptick in the number of credit card defaulters. Using this logic, credit card companies need a new way to decide whether or not to approve credit cards based on prior history. \n",
    "\n",
    "A previous study done by Dr. Hemkiran[1] evaluated whether applicants should be approved for a credit card by using a Logistic Regression with and without a grid search technique. They found that using a grid search technique improved the competency of their model. Additionally, they also used an Artificial Neural Network (ANN) and found it to be better than the linear regression model. Another study by Dr. Kibria[2] aimed to create a deep learning model to aid credit card approval decision-making. They also used a logistic regression model and a support vector machine (SVM) model to compare their results. They found that the deep learning model was better than the logistic regression and SVM models. However, the ANN model and deep learning model are more computationally expensive and time-consuming. \n",
    "\n",
    "We are attempting to create a predictive machine learning model that models whether or not the application has the right credentials to have their credit card application approved using the following variables: Applicant Gender, Owned property, Total Children, Owned Car, Total Income, Housing Type, Total Family Members, Applicant Age, Education Type, and Family Status. This is to avoid future credit card defaulters. We will use models such as Naive Bayes Classifier, Linear SVM, and Linear Regression and use them to compare our modelâ€™s performance as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "We are building this model to measure if there are any discrepancies when approving credit card applications. We additionally want to check if we could use big data and machine learning to build a model that predicts if a credit card is approved or not. This would take out human bias from the equation and make sure every application is fairly reviewed. Creating a machine learning model will attempt to eliminate the human bias towards race, class, gender, etc - an issue that plagues the financial ratings of individuals. Additionally, a machine-learning system can significantly reduce the human power and costs of a credit card company, increasing revenue. If our model can accurately predict whether an application can be accepted, we could conclude our hypothesis. This problem is quantifiable since we are trying to model a binary predictor. This problem is measurable because we would be using the metric of accuracy to validate the performance of our model. Lastly, our model is replicable because we could run it on different datasets and check its accuracy on each dataset. The model we will create will be composed of supervised machine-learning algorithms and techniques such as logistic regression, linear SVM, K fold validation, etc. We will train our model on previously collected data from credit card companies to understand what attributes make an individual more or less likely to get approved for a credit card. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- Link for our data: https://www.kaggle.com/datasets/caesarmario/application-data\n",
    "\n",
    "- This data set has about 25,100 observations with 21 variables. \n",
    "\n",
    "- The variables that will be used are Applicant Gender, Owned property, Total Children, Owned Car, Total Income, Housing Type, Total Family Members, Applicant Age, Education Type, and Family Status. \n",
    "\n",
    "- The dataset we are using has already been cleaned to drop any data points with null values and yet the dataset remains robust so we will not be addressing it any further.\n",
    "\n",
    "- We will additionally drop all the features that we will not be using to further declutter the dataset.\n",
    "\n",
    "- In addition to cleaning we one hot encoded all other categorical data which wasn't already binary which is displayed below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns    \n",
    "from matplotlib.pyplot import figure\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "#models importing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "#linear svm stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applicant_ID</th>\n",
       "      <th>Applicant_Gender</th>\n",
       "      <th>Owned_Car</th>\n",
       "      <th>Owned_Realty</th>\n",
       "      <th>Total_Children</th>\n",
       "      <th>Total_Income</th>\n",
       "      <th>Income_Type</th>\n",
       "      <th>Education_Type</th>\n",
       "      <th>Family_Status</th>\n",
       "      <th>Housing_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Owned_Work_Phone</th>\n",
       "      <th>Owned_Phone</th>\n",
       "      <th>Owned_Email</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Total_Family_Members</th>\n",
       "      <th>Applicant_Age</th>\n",
       "      <th>Years_of_Working</th>\n",
       "      <th>Total_Bad_Debt</th>\n",
       "      <th>Total_Good_Debt</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008806</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112500</td>\n",
       "      <td>Working                                       ...</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Married                                       ...</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff                                ...</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008808</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>Commercial associate                          ...</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff                                   ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008809</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>Commercial associate                          ...</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff                                   ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5008810</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>Commercial associate                          ...</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff                                   ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008811</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>Commercial associate                          ...</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff                                   ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Applicant_ID Applicant_Gender  Owned_Car  Owned_Realty  Total_Children  \\\n",
       "0       5008806          M                1             1               0   \n",
       "1       5008808          F                0             1               0   \n",
       "2       5008809          F                0             1               0   \n",
       "3       5008810          F                0             1               0   \n",
       "4       5008811          F                0             1               0   \n",
       "\n",
       "   Total_Income                                        Income_Type  \\\n",
       "0        112500  Working                                       ...   \n",
       "1        270000  Commercial associate                          ...   \n",
       "2        270000  Commercial associate                          ...   \n",
       "3        270000  Commercial associate                          ...   \n",
       "4        270000  Commercial associate                          ...   \n",
       "\n",
       "                                      Education_Type  \\\n",
       "0  Secondary / secondary special                 ...   \n",
       "1  Secondary / secondary special                 ...   \n",
       "2  Secondary / secondary special                 ...   \n",
       "3  Secondary / secondary special                 ...   \n",
       "4  Secondary / secondary special                 ...   \n",
       "\n",
       "                                       Family_Status  \\\n",
       "0  Married                                       ...   \n",
       "1  Single / not married                          ...   \n",
       "2  Single / not married                          ...   \n",
       "3  Single / not married                          ...   \n",
       "4  Single / not married                          ...   \n",
       "\n",
       "                                        Housing_Type  ...  Owned_Work_Phone  \\\n",
       "0  House / apartment                             ...  ...                 0   \n",
       "1  House / apartment                             ...  ...                 0   \n",
       "2  House / apartment                             ...  ...                 0   \n",
       "3  House / apartment                             ...  ...                 0   \n",
       "4  House / apartment                             ...  ...                 0   \n",
       "\n",
       "   Owned_Phone  Owned_Email  \\\n",
       "0            0            0   \n",
       "1            1            1   \n",
       "2            1            1   \n",
       "3            1            1   \n",
       "4            1            1   \n",
       "\n",
       "                                           Job_Title Total_Family_Members  \\\n",
       "0  Security staff                                ...                    2   \n",
       "1  Sales staff                                   ...                    1   \n",
       "2  Sales staff                                   ...                    1   \n",
       "3  Sales staff                                   ...                    1   \n",
       "4  Sales staff                                   ...                    1   \n",
       "\n",
       "   Applicant_Age  Years_of_Working  Total_Bad_Debt  Total_Good_Debt  Status  \n",
       "0             59                 4               0               30       1  \n",
       "1             53                 9               0                5       1  \n",
       "2             53                 9               0                5       1  \n",
       "3             53                 9               0               27       1  \n",
       "4             53                 9               0               39       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit  = pd.read_csv('Application_Data.csv')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004815345431391276\n"
     ]
    }
   ],
   "source": [
    "status = credit['Status']\n",
    "status_0_len = len(status[status==0])\n",
    "status_1_len = len(status[status==1])\n",
    "print(status_0_len/len(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: we noticed here that the datset mainly leading to approving the credit card, we cannot use a regualr model\n",
    "# because the best one would be just approving the credit card application every time. \n",
    "\n",
    "#we need to find a model that takes care of imbalanced data and looking fo that we found pyCaret. \n",
    "#we could also use scikit learn for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared the amount of positive and negative class data in our dataset and realized that less than 0.4% of our data was negative class. To handle this we have used SMOTE to generate more negative class data so the dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Applicant_ID             int64\n",
       "Applicant_Gender        object\n",
       "Owned_Car                int64\n",
       "Owned_Realty             int64\n",
       "Total_Children           int64\n",
       "Total_Income             int64\n",
       "Income_Type             object\n",
       "Education_Type          object\n",
       "Family_Status           object\n",
       "Housing_Type            object\n",
       "Owned_Mobile_Phone       int64\n",
       "Owned_Work_Phone         int64\n",
       "Owned_Phone              int64\n",
       "Owned_Email              int64\n",
       "Job_Title               object\n",
       "Total_Family_Members     int64\n",
       "Applicant_Age            int64\n",
       "Years_of_Working         int64\n",
       "Total_Bad_Debt           int64\n",
       "Total_Good_Debt          int64\n",
       "Status                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will only keep columns that we need. These columns are covered under Data along with \n",
    "#status which says whether or not it was approved\n",
    "credit = credit[[\"Applicant_Gender\", \"Applicant_Age\",\"Owned_Realty\",\n",
    "                 \"Total_Children\", \"Owned_Car\", \"Total_Income\", \"Housing_Type\",\n",
    "                 \"Total_Family_Members\", \"Education_Type\", \"Family_Status\", 'Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applicant_Gender</th>\n",
       "      <th>Applicant_Age</th>\n",
       "      <th>Owned_Realty</th>\n",
       "      <th>Total_Children</th>\n",
       "      <th>Owned_Car</th>\n",
       "      <th>Total_Income</th>\n",
       "      <th>Housing_Type</th>\n",
       "      <th>Total_Family_Members</th>\n",
       "      <th>Education_Type</th>\n",
       "      <th>Family_Status</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112500</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Married                                       ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000</td>\n",
       "      <td>House / apartment                             ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Secondary / secondary special                 ...</td>\n",
       "      <td>Single / not married                          ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Applicant_Gender  Applicant_Age  Owned_Realty  Total_Children  Owned_Car  \\\n",
       "0          M                   59             1               0          1   \n",
       "1          F                   53             1               0          0   \n",
       "2          F                   53             1               0          0   \n",
       "3          F                   53             1               0          0   \n",
       "4          F                   53             1               0          0   \n",
       "\n",
       "   Total_Income                                       Housing_Type  \\\n",
       "0        112500  House / apartment                             ...   \n",
       "1        270000  House / apartment                             ...   \n",
       "2        270000  House / apartment                             ...   \n",
       "3        270000  House / apartment                             ...   \n",
       "4        270000  House / apartment                             ...   \n",
       "\n",
       "   Total_Family_Members                                     Education_Type  \\\n",
       "0                     2  Secondary / secondary special                 ...   \n",
       "1                     1  Secondary / secondary special                 ...   \n",
       "2                     1  Secondary / secondary special                 ...   \n",
       "3                     1  Secondary / secondary special                 ...   \n",
       "4                     1  Secondary / secondary special                 ...   \n",
       "\n",
       "                                       Family_Status  Status  \n",
       "0  Married                                       ...       1  \n",
       "1  Single / not married                          ...       1  \n",
       "2  Single / not married                          ...       1  \n",
       "3  Single / not married                          ...       1  \n",
       "4  Single / not married                          ...       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(credit.dtypes)) #same as the number of columns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next we check for nulls and nans and if there exists any we will count them\n",
    "#and decide to drop the row containing that datapooint\n",
    "\n",
    "credit.isnull().values.any()\n",
    "#so there isnt any nan values so we dont need to replace any values anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Applicant_Gender        object\n",
       "Applicant_Age            int64\n",
       "Owned_Realty             int64\n",
       "Total_Children           int64\n",
       "Owned_Car                int64\n",
       "Total_Income             int64\n",
       "Housing_Type            object\n",
       "Total_Family_Members     int64\n",
       "Education_Type          object\n",
       "Family_Status           object\n",
       "Status                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next is making all columns which arent numerical numerical\n",
    "#first we will check which columns arent numerical\n",
    "credit.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlogisitic regression / classifier\\nada boost \\ngradient boost \\nrandom forests \\nSVM (radial kernel)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 possible models \n",
    "'''\n",
    "logisitic regression / classifier\n",
    "ada boost \n",
    "gradient boost \n",
    "random forests \n",
    "SVM (radial kernel)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our proposed solution to predicting whether individuals get approved for a credit card and understanding what variables play a role in making that decision is to use classifiers based on the techniques weâ€™ve learnt in class. \n",
    "First, we will use k-fold validation to determine our model of choice by validating over logistic classifiers/ regression, naive Bayes, Linear SVM, kernel ridge regression with l1, l2, and elastic net penalty. We will choose the model that gives us the highest accuracy score. \n",
    "We are using K-fold validation since with the train-validation-test model split we always run the issue of overfitting on the training data. K-fold validation instead trains and evaluates on all available data by splitting the data amongst each fold training on that and testing on the rest. \n",
    "We are using logistic classifiers/ regression, naive Bayes, Linear SVM, and kernel ridge regression since they are machine learning classifiers. Our proposed problem is to predict whether to approve a credit card for an applicant based on a variety of factors that were asked on their application. This is a yes or no question which makes it a binary classification task. As a result, it makes a lot of sense to use machine learning classification algorithms that can also be used to solve binary classification problems like the algorithms above. We are using these specific algorithms since we are familiar with these algorithms and understand how to run and evaluate them effectively. Furthermore, we use L1, L2, and elasticnet penalty on kernel ridge regression since these are regularization terms that will curb overfitting and make generalization better. \n",
    "With the chosen model we will validate across parameters. In the case of logistic regression, we will validate over the values of C = [0.01, 0.1, 1, 10, 100] to find our best model. \n",
    "For Naive Bayes, we will validate over Gaussian Naive Bayes and Multinomial Naive Bayes and choose our alpha from the following values - [0.01,0.05, 0.1, 0.2, 0.25].\n",
    "For Linear SVM, we will validate over different kernel functions - 'linear', 'poly', 'rbf', and 'sigmoid' and we will choose over values of C = [0.01, 0.1, 1, 10, 100] to find the best model. \n",
    "For Kernel Ridge, we will validate over the following values of alpha - [0.01, 0.1, 1.0, 10.0, 100.0], the kernel functions of linear, polynomial, and RBF and related kernel-specific parameters.\n",
    "Our extensive search over the models and their parameters will make our classification model accurate. As our dataset is not super large, we are not as concerned about computational efficiency - something to improve on while expanding on the project. \n",
    "We will finally train our model and test it to see its accuracy and compare it to existing models available on Kaggle to compare our performance. We will set up a confusion matrix to see how the model fares and plot the ROC/AUC. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will use both precision and recall metrics to evaluate our model as both false negatives and false positives are of significant concern to our model. A credit card company would need to maximize eligible customers to increase revenue by minimizing the number of false negatives and also would need to minimize the number of individuals who may default to cut losses hence minimizing the false positives. Since neither one of the metrics is more important to our model, we will additionally use the f1 score which incorporates both precision and recall to finally measure the performance of our model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Arenâ€™t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
